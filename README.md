# ğŸš— Car Price Prediction

Proyecto para predecir el **valor de mercado de coches de segunda mano** utilizando diferentes modelos de machine learning, optimizando precisiÃ³n, velocidad de predicciÃ³n y tiempo de entrenamiento.

---

## ğŸ“˜ DescripciÃ³n del proyecto
Rusty Bargain es un servicio de venta de coches de segunda mano que desarrolla una app para que los usuarios conozcan rÃ¡pidamente el valor de su vehÃ­culo.  
Se dispone de datos histÃ³ricos, especificaciones tÃ©cnicas, versiones de equipamiento y precios.

El objetivo es crear un modelo que determine el **precio del vehÃ­culo (`Price`)** y analizar el balance entre:

- Calidad de la predicciÃ³n  
- Velocidad de predicciÃ³n  
- Tiempo de entrenamiento  

---

## ğŸ—‚ Dataset
Archivo: `/datasets/car_data.csv`  

**CaracterÃ­sticas principales:**
- `DateCrawled` â€” fecha de descarga del perfil  
- `VehicleType` â€” tipo de carrocerÃ­a  
- `RegistrationYear` â€” aÃ±o de matriculaciÃ³n  
- `Gearbox` â€” tipo de caja de cambios  
- `Power` â€” potencia (CV)  
- `Model` â€” modelo del vehÃ­culo  
- `Mileage` â€” kilometraje (km)  
- `RegistrationMonth` â€” mes de matriculaciÃ³n  
- `FuelType` â€” tipo de combustible  
- `Brand` â€” marca del vehÃ­culo  
- `NotRepaired` â€” si el vehÃ­culo ha sido reparado  
- `DateCreated` â€” fecha de creaciÃ³n del perfil  
- `NumberOfPictures` â€” nÃºmero de fotos  
- `PostalCode` â€” cÃ³digo postal del propietario  
- `LastSeen` â€” Ãºltima fecha de actividad  

**Objetivo:**  
- `Price` â€” precio en euros  

---

## ğŸ› ï¸ Proceso del proyecto

### 1. PreparaciÃ³n de datos
- ExploraciÃ³n y limpieza del dataset  
- CodificaciÃ³n de variables categÃ³ricas segÃºn el algoritmo  
- DivisiÃ³n en conjuntos de entrenamiento y prueba  
- MediciÃ³n de tiempos de ejecuciÃ³n para entrenamiento y predicciÃ³n  

---

### 2. Entrenamiento y evaluaciÃ³n de modelos
Se entrenaron mÃºltiples modelos con distintos hiperparÃ¡metros:

- **Linear Regression** â€“ prueba de cordura (RMSE=3172.36)  
- **Decision Tree** â€“ muy rÃ¡pido pero alto error (RMSE=2191.97)  
- **Random Forest** â€“ menor error (RMSE=1736.32) pero entrenamiento lento (>1100s)  
- **LightGBM** â€“ buen equilibrio velocidad/precisiÃ³n (RMSE=1792.44)  
- **XGBoost** â€“ similar a LightGBM (RMSE=1814.79)  
- **LightGBM_2 y CatBoost** â€“ rendimiento aceptable (RMSEâ‰ˆ1847), pero sin destacar frente a los anteriores  

**MÃ©trica utilizada:** RECM / RMSE  

---

### 3. Observaciones
- RegresiÃ³n lineal confirma que los modelos complejos aportan valor.  
- Decision Tree es rÃ¡pido pero poco preciso.  
- Random Forest es mÃ¡s preciso, pero muy costoso computacionalmente.  
- LightGBM y XGBoost ofrecen **el mejor balance entre velocidad y precisiÃ³n**, siendo ideales para una app que requiera predicciones rÃ¡pidas y confiables.  

---

## ğŸ† ConclusiÃ³n
- **Si priorizamos precisiÃ³n:** Random Forest  
- **Si priorizamos eficiencia y precisiÃ³n equilibrada:** LightGBM o XGBoost  

---

## ğŸ§° TecnologÃ­as utilizadas
- Python  
- pandas Â· numpy  
- scikit-learn  
- LightGBM Â· XGBoost Â· CatBoost  
- matplotlib / seaborn  
