{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ebfa70",
   "metadata": {},
   "source": [
    "# Rusty Bargain - Modelo de valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a312b",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9335efe9",
   "metadata": {},
   "source": [
    "## 0. Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee001fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f73f8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar LightGBM, CatBoost y XGBoost\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    !pip install lightgbm --quiet\n",
    "    import lightgbm as lgb\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "except Exception:\n",
    "    !pip install catboost --quiet\n",
    "    from catboost import CatBoostRegressor\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    !pip install xgboost --quiet\n",
    "    import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83031b68",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e63714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
      "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
      "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
      "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
      "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
      "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
      "\n",
      "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
      "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
      "1    NaN   125000                  5  gasoline        audi         yes   \n",
      "2  grand   125000                  8  gasoline        jeep         NaN   \n",
      "3   golf   150000                  6    petrol  volkswagen          no   \n",
      "4  fabia    90000                  7  gasoline       skoda          no   \n",
      "\n",
      "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
      "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
      "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
      "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
      "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
      "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n",
      "None\n",
      "DateCrawled              0\n",
      "Price                    0\n",
      "VehicleType          37490\n",
      "RegistrationYear         0\n",
      "Gearbox              19833\n",
      "Power                    0\n",
      "Model                19705\n",
      "Mileage                  0\n",
      "RegistrationMonth        0\n",
      "FuelType             32895\n",
      "Brand                    0\n",
      "NotRepaired          71154\n",
      "DateCreated              0\n",
      "NumberOfPictures         0\n",
      "PostalCode               0\n",
      "LastSeen                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('car_data.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9138c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir features y target\n",
    "features_col = ['VehicleType', 'RegistrationYear', 'Gearbox', 'Power',\n",
    "                'Model', 'Mileage', 'RegistrationMonth', 'FuelType', 'Brand', 'NotRepaired']\n",
    "target_col = 'Price'\n",
    "\n",
    "features = df[features_col]\n",
    "target = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4199336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd877b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento\n",
    "num_cols = features.select_dtypes(\n",
    "    include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = features.select_dtypes(\n",
    "    include=['object', 'category']).columns.tolist()\n",
    "num_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='median'), StandardScaler())\n",
    "cat_transformer = make_pipeline(SimpleImputer(\n",
    "    strategy='constant', fill_value='missing'), OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "cat_nan_transformer = make_pipeline(SimpleImputer(\n",
    "    strategy='constant', fill_value='missing'))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [('num', num_transformer, num_cols), ('cat', cat_transformer, cat_cols)], remainder='drop')\n",
    "preprocessor_nan = ColumnTransformer(\n",
    "    [('num', num_transformer, num_cols), ('cat', cat_nan_transformer, cat_cols)], remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc9a49",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed856e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar modelos\n",
    "def evaluate_model(name, model, features_train, target_train, features_test, target_test, cat_features=None):\n",
    "    # Train model\n",
    "    start_train = time.time()\n",
    "    if name in ['CatBoost'] and cat_features is not None:\n",
    "        null_columns = features_train.columns[features_train.isnull().any()]\n",
    "        for col in null_columns:\n",
    "            features_train[col] = features_train[col].fillna(\n",
    "                'missing').astype(str)\n",
    "            features_test[col] = features_test[col].fillna(\n",
    "                'missing').astype(str)\n",
    "        model.fit(features_train, target_train,\n",
    "                  cat_features=cat_features, verbose=0)\n",
    "        pipe = model\n",
    "    else:\n",
    "        pipe = make_pipeline(preprocessor, model)\n",
    "        pipe.fit(features_train, target_train)\n",
    "    train_time = time.time() - start_train\n",
    "\n",
    "    # Predict\n",
    "    start_pred = time.time()\n",
    "    pred = pipe.predict(features_test)\n",
    "    pred_time = time.time() - start_pred\n",
    "    pred_time_per_sample = pred_time / features_test.shape[0]\n",
    "\n",
    "    total_time = train_time + pred_time\n",
    "    rmse = root_mean_squared_error(target_test, pred)\n",
    "    print(f\"{name}: train={train_time:.3f}s, pred={pred_time:.3f}s ({pred_time_per_sample:.6f}s/sample), total={total_time:.3f}s, RECM(RMSE)={rmse:.2f}\")\n",
    "    return {'model': name, 'rmse': rmse, 'train_time_s': train_time, 'pred_time_per_sample_s': pred_time_per_sample, 'total_time_s': total_time, 'pipe': pipe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a159367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=12345),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=12345),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=200, learning_rate=0.1, n_jobs=-1, verbose=-1, force_row_wise=True, random_state=12345),\n",
    "    'LightGBM_2': lgb.LGBMRegressor(n_estimators=200, learning_rate=0.05, max_depth=12, n_jobs=-1, verbose=-1, force_row_wise=True, random_state=12345),\n",
    "    'CatBoost': CatBoostRegressor(iterations=200, learning_rate=0.1, verbose=0, random_seed=12345),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, n_jobs=-1, random_state=12345)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30756ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar índices de features categóricas\n",
    "cat_features_cols = features_train.select_dtypes(\n",
    "    include=['object', 'category']).columns.tolist()\n",
    "cat_features_idx = [features_train.columns.get_loc(\n",
    "    c) for c in cat_features_cols] if cat_features_cols else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4643a2",
   "metadata": {},
   "source": [
    "## 3. Análisis de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a9a2edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: train=9.109s, pred=0.487s (0.000007s/sample), total=9.596s, RECM(RMSE)=3172.36\n",
      "DecisionTree: train=46.351s, pred=0.456s (0.000006s/sample), total=46.807s, RECM(RMSE)=2191.97\n",
      "RandomForest: train=1803.793s, pred=4.407s (0.000062s/sample), total=1808.199s, RECM(RMSE)=1736.32\n",
      "LightGBM: train=6.863s, pred=0.762s (0.000011s/sample), total=7.624s, RECM(RMSE)=1792.44\n",
      "LightGBM_2: train=21.870s, pred=0.625s (0.000009s/sample), total=22.494s, RECM(RMSE)=1847.40\n",
      "CatBoost: train=39.998s, pred=0.266s (0.000004s/sample), total=40.265s, RECM(RMSE)=1847.02\n",
      "XGBoost: train=10.107s, pred=0.448s (0.000006s/sample), total=10.556s, RECM(RMSE)=1814.79\n"
     ]
    }
   ],
   "source": [
    "# Función para evaluar modelos\n",
    "results = []\n",
    "for name, m in models.items():\n",
    "    if name == 'CatBoost':\n",
    "        res = evaluate_model(name, m, features_train, target_train,\n",
    "                             features_test, target_test, cat_features=cat_features_idx)\n",
    "    else:\n",
    "        res = evaluate_model(name, m, features_train,\n",
    "                             target_train, features_test, target_test)\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3371e6",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696eae4",
   "metadata": {},
   "source": [
    "- LinearRegression utilizado como prueba de cordura tuvo un error muy alto (RMSE=3172.36), confirmando que los modelos más complejos sí aportan valor.\n",
    "- DecisionTree es el modelo más simple: entrena y predice muy rápido, pero su error (RMSE=2191.97) es el más alto, lo que indica baja capacidad de generalización.\n",
    "- RandomForest logra el mejor desempeño en términos de error (RMSE=1736.32), pero a costa de un tiempo de entrenamiento extremadamente alto (más de 1100 segundos), lo que lo hace poco eficiente frente a los demás.\n",
    "- LightGBM y XGBoost ofrecen un balance muy favorable entre precisión y velocidad: entrenan en segundos, predicen casi instantáneamente y mantienen errores relativamente bajos (1792.44 y 1814.79, respectivamente).\n",
    "- LightGBM_2 y CatBoost tienen un rendimiento similar, con errores algo mayores (1847.40 y 1847.02), sin destacar frente a LightGBM ni XGBoost en velocidad o precisión.\n",
    "\n",
    "\n",
    "- Si priorizamos precisión, RandomForest es el ganador, aunque con un costo computacional elevado.\n",
    "- Si buscamos el mejor equilibrio entre precisión y eficiencia, LightGBM y XGBoost son las mejores opciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
